# LiteLLM Configuration for qlib_rd_agent
# Maps OpenAI-compatible model names to actual backends
#
# STRATEGY: Volcengine Coding Endpoint via OpenAI Provider
# 1. Base URL: https://ark.cn-beijing.volces.com/api/coding/v3
# 2. Provider: "openai" (bypasses LiteLLM's strict "volcengine" provider checks)
# 3. Models: Maps standard OpenAI names (gpt-4o) to Volcengine model IDs
#    - We use "openai/glm-4-7-251222" to target the specific GLM-4 model
#    - The "coding" endpoint allows more flexible model naming than standard api/v3
#
# Usage: Set LITELLM_CONFIG_PATH=litellm_config.yaml in .env

model_list:
  # ── Chat models: Volcengine glm-4.7 ──────────────────────────────
  # RD-Agent calls "gpt-4o" or similar → routed to Volcengine glm-4.7
  - model_name: "volcengine/glm-4.7"
    litellm_params:
      model: "openai/glm-4.7"  # Use openai provider to bypass strict checks
      api_key: "os.environ/VOLCENGINE_API_KEY"
      api_base: "os.environ/VOLCENGINE_BASE_URL"
      drop_params: true
      
  - model_name: "gpt-4o"
    litellm_params:
      model: "openai/glm-4.7"
      api_key: "os.environ/VOLCENGINE_API_KEY"
      api_base: "os.environ/VOLCENGINE_BASE_URL"
      drop_params: true

  - model_name: "gpt-4o-mini"
    litellm_params:
      model: "openai/glm-4.7"  # Map mini to same strong model for now
      api_key: "os.environ/VOLCENGINE_API_KEY"
      api_base: "os.environ/VOLCENGINE_BASE_URL"
      drop_params: true

  - model_name: "gpt-4"
    litellm_params:
      model: "openai/glm-4.7"
      api_key: "os.environ/VOLCENGINE_API_KEY"
      api_base: "os.environ/VOLCENGINE_BASE_URL"
      drop_params: true

  - model_name: "gpt-3.5-turbo"
    litellm_params:
      model: "openai/glm-4.7"
      api_key: "os.environ/VOLCENGINE_API_KEY"
      api_base: "os.environ/VOLCENGINE_BASE_URL"
      drop_params: true

  # ── Embedding models: AIHUBMIX text-embedding-3-small ─────────────
  # RD-Agent calls "text-embedding-3-small" or similar → routed to AIHUBMIX
  - model_name: "text-embedding-3-small"
    litellm_params:
      model: "openai/text-embedding-3-small"
      api_key: "os.environ/AIHUBMIX_API_KEY"
      api_base: "os.environ/AIHUBMIX_BASE_URL"

  - model_name: "text-embedding-3-large"
    litellm_params:
      model: "openai/text-embedding-3-small"
      api_key: "os.environ/AIHUBMIX_API_KEY"
      api_base: "os.environ/AIHUBMIX_BASE_URL"

  - model_name: "text-embedding-ada-002"
    litellm_params:
      model: "openai/text-embedding-3-small"
      api_key: "os.environ/AIHUBMIX_API_KEY"
      api_base: "os.environ/AIHUBMIX_BASE_URL"

# General settings
litellm_settings:
  drop_params: true  # Silently drop unsupported params
  set_verbose: false
  num_retries: 3
  request_timeout: 120
